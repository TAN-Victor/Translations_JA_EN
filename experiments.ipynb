{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Machine Translation of News: Japanese to English Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental part - Not really meant to be run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "import torch\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ======================================================================\n",
    "### OPTIONAL IMPORTS, SEE REPORT FOR DETAILS\n",
    "### ======================================================================\n",
    "# from googletrans import Translator\n",
    "#\n",
    "# import spacy\n",
    "# import Mykytea\n",
    "# import MeCab\n",
    "#\n",
    "# from sumy import Summarizer\n",
    "# from sumy.parsers.plaintext import PlaintextParser\n",
    "# from sumy.nlp.tokenizers import Tokenizer\n",
    "# from sumy.nlp.stemmers import Stemmer\n",
    "# from sumy.utils import get_stop_words\n",
    "# from sumy.summarizers.lsa import LsaSummarizer\n",
    "### ======================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "cache_dir = '/work/victota/.cache'                                # Because I lacked space in my main disk\n",
    "dataset_dir = '/work/victota/traintmp'                            # Directory where the dataset is stored, as dataset.Dataset object\n",
    "dataframe_dir = '/work/victota/dataframe'                         # Directory where the dataframe is stored, as pandas.DataFrame object\n",
    "max_length = 256                                                  # Maximum length of input sequence and output sequence for tokenizer and model generation\n",
    "num_beams = 4                                                     # Number of beams for beam search during model generation, higher is slower but sometimes better in quality\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('Helsinki-NLP/opus-mt-ja-en', cache_dir=cache_dir)                     # Will be MarianTokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('Helsinki-NLP/opus-mt-ja-en', cache_dir=cache_dir).to(device)      # Will be MarianMTModel\n",
    "\n",
    "\n",
    "### ======================================================================\n",
    "### OPTIONAL, SEE REPORT FOR DETAILS\n",
    "### ======================================================================\n",
    "# tokenizer2 = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50', cache_dir=cache_dir, src_lang=\"ja_XX\", tgt_lang=\"en_XX\")               \n",
    "# model2 = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50', cache_dir=cache_dir).to(device)\n",
    "# mk = Mykytea.Mykytea(\"-model /work/victota/TDT4310/Helsinki/jp-0.4.7-1.mod\")\n",
    "# nlp = spacy.load(\"ja_core_news_md\")\n",
    "# mecab = MeCab.Tagger(\"-Owakati\")\n",
    "# translator = Translator()\n",
    "### ======================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(model, tokenizer, input_text, is_split_into_words: bool):\n",
    "    \"\"\"\n",
    "    Translate input text using model and tokenizer\n",
    "\n",
    "    Parameters:\n",
    "        model: Model to use for translation\n",
    "        tokenizer: Tokenizer to use for translation\n",
    "        input_text: Text to translate\n",
    "        is_split_into_words: If input text is already segmented\n",
    "\n",
    "    Returns:\n",
    "        Translated text\n",
    "    \"\"\"\n",
    "    # Tokenize the input text and convert it to tensors (IDs)\n",
    "        # Will both SEGMENT and ENCODE if is_split_into_words is False\n",
    "        # Will only ENCODE if is_split_into_words is True\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_length, is_split_into_words=is_split_into_words).to(device)\n",
    "    \n",
    "    # Generate translation using model\n",
    "    translated = model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=max_length, num_beams=num_beams, early_stopping=True)\n",
    "\n",
    "    # Decode the output tokens to text\n",
    "    decoded_output = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "\n",
    "    return decoded_output\n",
    "\n",
    "\n",
    "def calculate_bleu_score(predictions, references, max_order=4):\n",
    "    \"\"\"\n",
    "    Compute BLEU score for predictions and references\n",
    "\n",
    "    Parameters:\n",
    "        predictions: List of predicted translations\n",
    "        references: List of reference translations\n",
    "        max_order: Maximum order of n-grams to consider, default is 4\n",
    "\n",
    "    Returns:\n",
    "        BLEU score for the predictions and references\n",
    "    \"\"\"\n",
    "    bleu = evaluate.load(\"bleu\", cache_dir=cache_dir)\n",
    "    return bleu.compute(predictions=predictions, references=references, max_order=max_order)\n",
    "\n",
    "def calculate_rouge_score(predictions, references):\n",
    "    \"\"\"\n",
    "    Compute ROUGE score for predictions and references\n",
    "\n",
    "    Parameters:\n",
    "        predictions: List of predicted translations\n",
    "        references: List of reference translations\n",
    "\n",
    "    Returns:\n",
    "        ROUGE score for the predictions and references\n",
    "    \"\"\"\n",
    "    rouge = evaluate.load(\"rouge\", cache_dir=cache_dir)\n",
    "    return rouge.compute(predictions=predictions, references=references)\n",
    "\n",
    "def calculate_chrf_score(predictions, references):\n",
    "    \"\"\"\n",
    "    Compute chrF score for predictions and references\n",
    "\n",
    "    Parameters:\n",
    "        predictions: List of predicted translations\n",
    "        references: List of reference translations\n",
    "\n",
    "    Returns:\n",
    "        chrF score for the predictions and references\n",
    "    \"\"\"\n",
    "    chrf = evaluate.load(\"chrf\", cache_dir=cache_dir)\n",
    "    return chrf.compute(predictions=predictions, references=references)\n",
    "\n",
    "def calculate_bleurt_score(predictions, references):\n",
    "    \"\"\"\n",
    "    Compute Bleurt score for predictions and references\n",
    "    Could be used for evaluating translations, but we didn't find the Bleurt scores of WMT23,\n",
    "    so couldn't compare\n",
    "\n",
    "    Parameters:\n",
    "        predictions: List of predicted translations\n",
    "        references: List of reference translations\n",
    "\n",
    "    Returns:\n",
    "        Bleurt score for the predictions and references\n",
    "    \"\"\"\n",
    "    bleurt = evaluate.load(\"bleurt\", cache_dir=cache_dir)\n",
    "    return bleurt.compute(predictions=predictions, references=references)\n",
    "\n",
    "def calculate_comet_score(sources, predictions, references):\n",
    "    \"\"\"\n",
    "    Compute COMET score for predictions and references\n",
    "\n",
    "    Parameters:\n",
    "        sources: List of source translations\n",
    "        predictions: List of predicted translations\n",
    "        references: List of reference translations\n",
    "\n",
    "    Returns:\n",
    "        COMET score for the predictions and references\n",
    "    \"\"\"\n",
    "    comet = evaluate.load(\"comet\", cache_dir=cache_dir)\n",
    "    return comet.compute(sources=sources, predictions=predictions, references=references)\n",
    "\n",
    "\n",
    "def contains_chinese_jap(sentence):\n",
    "    \"\"\"\n",
    "    Determine if the sentence contains Chinese or Japanese characters\n",
    "\n",
    "    Parameters:\n",
    "        sentence: Sentence\n",
    "\n",
    "    Returns:\n",
    "        Bool \n",
    "    \"\"\"\n",
    "    for c in sentence:\n",
    "        if (ord(c) >= 0x4E00 and ord(c) <= 0x9FFF) or (ord(c) >= 0x3400 and ord(c) <= 0x4DFF) or (ord(c) >= 0x20000 and ord(c) <= 0x2A6DF) or (ord(c) >= 0x2A700 and ord(c) <= 0x2B73F) or (ord(c) >= 0x2B740 and ord(c) <= 0x2B81F) or (ord(c) >= 0x2B820 and ord(c) <= 0x2CEAF) or (ord(c) >= 0xF900 and ord(c) <= 0xFAFF):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Note: The dataset used was originally preprocessed for Mistral 7B fine-tuning, with \"text\" as the prompt. It is here not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_from_disk(dataset_dir)\n",
    "# df = data.to_pandas()\n",
    "# df.drop([\"text\"], axis=1, inplace=True)\n",
    "# df.dropna(inplace=True)\n",
    "# data = df.sample(150000, random_state=42)\n",
    "# data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(data[data['jp'].str.contains('[a-zA-Z]')].index, inplace=True)        # Remove lines with English characters in Japanese sentences\n",
    "# data = data[data.apply(lambda x: not contains_chinese_jap(x['en']), axis=1)]    # Remove lines with Chinese or Japanese characters in English sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>jp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The company is targeting to increase the number of female staff in managerial positions in various business areas in the medium- to long-term.</td>\n",
       "      <td>今後、あらゆる領域で更に女性が活 躍し、管理職を担う女性が中長期的に増加することをめざしています。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today there are an overwhelming number of payment methods available.</td>\n",
       "      <td>銀行送金に対応している全体的なブックメーカーの数はまだまだ少ないのが現状です。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There are many pieces that are simple, yet having a fairy-tale like ambience, so I think that anyone will be able to easily appreciate the works.</td>\n",
       "      <td>シンプルながらも童話のような感じを与える作品が多く、誰でも簡単に共感できると感じます。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Another area of private standard-setting to emerge in the late 1990’s concerned social or sustainability reporting.</td>\n",
       "      <td>1990 年代後半に民間の規格設定が出現した別の領域は、社会的又は持続的発展報告 に係わるものであった。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As the last bit of light fades enjoy the scenery as you sail past ancient communities of fishermen that have lived for generations in floating villages on the water.</td>\n",
       "      <td>光の最後のビットは、あなたが水上の浮遊村で世代のために住んでいる古代の漁師のコミュニティを越えて航海するとき、景色を楽しむようになります。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                      en  \\\n",
       "0                         The company is targeting to increase the number of female staff in managerial positions in various business areas in the medium- to long-term.   \n",
       "1                                                                                                   Today there are an overwhelming number of payment methods available.   \n",
       "2                      There are many pieces that are simple, yet having a fairy-tale like ambience, so I think that anyone will be able to easily appreciate the works.   \n",
       "3                                                    Another area of private standard-setting to emerge in the late 1990’s concerned social or sustainability reporting.   \n",
       "4  As the last bit of light fades enjoy the scenery as you sail past ancient communities of fishermen that have lived for generations in floating villages on the water.   \n",
       "\n",
       "                                                                      jp  \n",
       "0                      今後、あらゆる領域で更に女性が活 躍し、管理職を担う女性が中長期的に増加することをめざしています。  \n",
       "1                                銀行送金に対応している全体的なブックメーカーの数はまだまだ少ないのが現状です。  \n",
       "2                            シンプルながらも童話のような感じを与える作品が多く、誰でも簡単に共感できると感じます。  \n",
       "3                   1990 年代後半に民間の規格設定が出現した別の領域は、社会的又は持続的発展報告 に係わるものであった。  \n",
       "4  光の最後のビットは、あなたが水上の浮遊村で世代のために住んでいる古代の漁師のコミュニティを越えて航海するとき、景色を楽しむようになります。  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_dataset_jp(data):\n",
    "    lang = \"japanese\"\n",
    "    stemmer = Stemmer(lang)\n",
    "    tokenizer = Tokenizer(lang)\n",
    "    summarizer = LsaSummarizer(stemmer)\n",
    "    summarizer.stop_words = get_stop_words(lang)\n",
    "    data[\"summarized_jp\"] = \"\"\n",
    "    for _, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        text = row['jp']\n",
    "        parser = PlaintextParser.from_string(text, tokenizer)\n",
    "        summary_sentences = summarizer(parser.document, 1)\n",
    "        data.at[_, \"summarized_jp\"] = \" \".join(str(sentence) for sentence in summary_sentences) # In case more than 1\n",
    "    return data\n",
    "\n",
    "def summarize_dataset_en(data):\n",
    "    lang = \"english\"\n",
    "    stemmer = Stemmer(lang)\n",
    "    tokenizer = Tokenizer(lang)\n",
    "    summarizer = LsaSummarizer(stemmer)\n",
    "    summarizer.stop_words = get_stop_words(lang)\n",
    "    data[\"summarized_en\"] = \"\"\n",
    "    for _, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        text = row['en']\n",
    "        parser = PlaintextParser.from_string(text, tokenizer)\n",
    "        summary_sentences = summarizer(parser.document, 1)\n",
    "        data.at[_, \"summarized_en\"] = \" \".join(str(sentence) for sentence in summary_sentences) # In case more than 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>jp</th>\n",
       "      <th>summarized_jp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The company is targeting to increase the number of female staff in managerial positions in various business areas in the medium- to long-term.</td>\n",
       "      <td>今後、あらゆる領域で更に女性が活 躍し、管理職を担う女性が中長期的に増加することをめざしています。</td>\n",
       "      <td>今後、あらゆる領域で更に女性が活 躍し、管理職を担う女性が中長期的に増加することをめざしています。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today there are an overwhelming number of payment methods available.</td>\n",
       "      <td>銀行送金に対応している全体的なブックメーカーの数はまだまだ少ないのが現状です。</td>\n",
       "      <td>銀行送金に対応している全体的なブックメーカーの数はまだまだ少ないのが現状です。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There are many pieces that are simple, yet having a fairy-tale like ambience, so I think that anyone will be able to easily appreciate the works.</td>\n",
       "      <td>シンプルながらも童話のような感じを与える作品が多く、誰でも簡単に共感できると感じます。</td>\n",
       "      <td>シンプルながらも童話のような感じを与える作品が多く、誰でも簡単に共感できると感じます。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Another area of private standard-setting to emerge in the late 1990’s concerned social or sustainability reporting.</td>\n",
       "      <td>1990 年代後半に民間の規格設定が出現した別の領域は、社会的又は持続的発展報告 に係わるものであった。</td>\n",
       "      <td>1990 年代後半に民間の規格設定が出現した別の領域は、社会的又は持続的発展報告 に係わるものであった。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As the last bit of light fades enjoy the scenery as you sail past ancient communities of fishermen that have lived for generations in floating villages on the water.</td>\n",
       "      <td>光の最後のビットは、あなたが水上の浮遊村で世代のために住んでいる古代の漁師のコミュニティを越えて航海するとき、景色を楽しむようになります。</td>\n",
       "      <td>光の最後のビットは、あなたが水上の浮遊村で世代のために住んでいる古代の漁師のコミュニティを越えて航海するとき、景色を楽しむようになります。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                      en  \\\n",
       "0                         The company is targeting to increase the number of female staff in managerial positions in various business areas in the medium- to long-term.   \n",
       "1                                                                                                   Today there are an overwhelming number of payment methods available.   \n",
       "2                      There are many pieces that are simple, yet having a fairy-tale like ambience, so I think that anyone will be able to easily appreciate the works.   \n",
       "3                                                    Another area of private standard-setting to emerge in the late 1990’s concerned social or sustainability reporting.   \n",
       "4  As the last bit of light fades enjoy the scenery as you sail past ancient communities of fishermen that have lived for generations in floating villages on the water.   \n",
       "\n",
       "                                                                      jp  \\\n",
       "0                      今後、あらゆる領域で更に女性が活 躍し、管理職を担う女性が中長期的に増加することをめざしています。   \n",
       "1                                銀行送金に対応している全体的なブックメーカーの数はまだまだ少ないのが現状です。   \n",
       "2                            シンプルながらも童話のような感じを与える作品が多く、誰でも簡単に共感できると感じます。   \n",
       "3                   1990 年代後半に民間の規格設定が出現した別の領域は、社会的又は持続的発展報告 に係わるものであった。   \n",
       "4  光の最後のビットは、あなたが水上の浮遊村で世代のために住んでいる古代の漁師のコミュニティを越えて航海するとき、景色を楽しむようになります。   \n",
       "\n",
       "                                                           summarized_jp  \n",
       "0                      今後、あらゆる領域で更に女性が活 躍し、管理職を担う女性が中長期的に増加することをめざしています。  \n",
       "1                                銀行送金に対応している全体的なブックメーカーの数はまだまだ少ないのが現状です。  \n",
       "2                            シンプルながらも童話のような感じを与える作品が多く、誰でも簡単に共感できると感じます。  \n",
       "3                   1990 年代後半に民間の規格設定が出現した別の領域は、社会的又は持続的発展報告 に係わるものであった。  \n",
       "4  光の最後のビットは、あなたが水上の浮遊村で世代のために住んでいる古代の漁師のコミュニティを越えて航海するとき、景色を楽しむようになります。  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize = summarize_dataset_jp(data)\n",
    "# summarize.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/work/victota/TDT4310/Helsinki/translated_no_eng_nocnjp_google.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation(model, tokenizer, data, segmentation= None):\n",
    "    \"\"\"\n",
    "    Translate the data using the model and tokenizer\n",
    "\n",
    "    Parameters:\n",
    "        model: Model to use for translation\n",
    "        tokenizer: Tokenizer to use for translation\n",
    "        data: Data to translate\n",
    "        segmentation: Segmentation method to use for translation, can be [None, \"mecab\", \"mykytea\", \"spacy\"]\n",
    "\n",
    "    Returns:\n",
    "        Data with translated text\n",
    "    \"\"\"\n",
    "    data[\"prediction\"] = \"\"\n",
    "    print(\"Len: \", len(data))\n",
    "    for _, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        # input_text = \"\"                                        # Optional segmentation\n",
    "        # if segmentation == \"mecab\":\n",
    "        #     input_text = mecab.parse(row['jp'])\n",
    "        # elif segmentation == \"mykytea\":\n",
    "        #     tokens = mk.getWS(row['jp'])\n",
    "        #     for token in tokens:\n",
    "        #         input_text += token + \" \"\n",
    "        # elif segmentation == \"spacy\":\n",
    "        #     doc = nlp(row['jp'])\n",
    "        #     for token in doc:\n",
    "        #         input_text += token.text + \" \"\n",
    "        # else:\n",
    "        #     input_text = row['jp']\n",
    "        input_text = row['jp']\n",
    "        prediction = translate_text(model, tokenizer, input_text, is_split_into_words= segmentation in [\"mecab\", \"mykytea\", \"spacy\"])\n",
    "\n",
    "        data.at[_, 'prediction'] = prediction\n",
    "\n",
    "    bleu_score = calculate_bleu_score(data['prediction'].tolist(), data['en'].tolist())\n",
    "    rouge_score = calculate_rouge_score(data['prediction'].tolist(), data['en'].tolist())\n",
    "    chrf_score = calculate_chrf_score(data['prediction'].tolist(), data['en'].tolist())\n",
    "    bleurt_score = calculate_bleurt_score(data['prediction'].tolist(), data['en'].tolist())\n",
    "    comet_score = calculate_comet_score(data['jp'].tolist(), data['prediction'].tolist(), data['en'].tolist())\n",
    "    print(f\"BLEU score: {bleu_score}\")\n",
    "    print(f\"ROUGE score: {rouge_score}\")\n",
    "    print(f\"CHRF score: {chrf_score}\")\n",
    "    print(f\"Bleurt score: {sum(bleurt_score['scores']) / len(bleurt_score['scores'])}\")\n",
    "    print(f\"COMET score: {comet_score['mean_score']}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "translated = translation(model, tokenizer, test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translated.to_csv(\"XXXXXXX.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation_google(data):\n",
    "    \"\"\"\n",
    "    Translate the data using Google Translate\n",
    "\n",
    "    Parameters:\n",
    "        data: Dataframe to translate\n",
    "\n",
    "    Returns:\n",
    "        Dataframe with translated text\n",
    "    \"\"\"\n",
    "    for _, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        if data[\"google_translation\"].isna().iloc[_] == False:             # Skip if already translated\n",
    "            continue\n",
    "        input_text = row['jp']\n",
    "        translation = translator.translate(input_text, src='ja', dest='en')\n",
    "\n",
    "        data.at[_, 'google_translation'] = translation.text\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>jp</th>\n",
       "      <th>google_translation</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The company is targeting to increase the number of female staff in managerial positions in various business areas in the medium- to long-term.</td>\n",
       "      <td>今後、あらゆる領域で更に女性が活 躍し、管理職を担う女性が中長期的に増加することをめざしています。</td>\n",
       "      <td>Going forward, we aim to encourage more women to play an active role in all fields, and to increase the number of women in managerial positions over the medium to long term.</td>\n",
       "      <td>From now on, women in all walks of life and in all walks of life will be able to increase in the middle-term women who are more active and more active and more executive.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today there are an overwhelming number of payment methods available.</td>\n",
       "      <td>銀行送金に対応している全体的なブックメーカーの数はまだまだ少ないのが現状です。</td>\n",
       "      <td>The current situation is that the overall number of bookmakers that support bank transfers is still small.</td>\n",
       "      <td>The total number of bookmakers corresponding to bank transfers is still small.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There are many pieces that are simple, yet having a fairy-tale like ambience, so I think that anyone will be able to easily appreciate the works.</td>\n",
       "      <td>シンプルながらも童話のような感じを与える作品が多く、誰でも簡単に共感できると感じます。</td>\n",
       "      <td>Although many of the works are simple, they have a fairy tale-like feel, and I feel that anyone can easily relate to them.</td>\n",
       "      <td>There are many simple works that give you the feeling of being a fairy tale, and I find it easy to sympathize with anyone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Another area of private standard-setting to emerge in the late 1990’s concerned social or sustainability reporting.</td>\n",
       "      <td>1990 年代後半に民間の規格設定が出現した別の領域は、社会的又は持続的発展報告 に係わるものであった。</td>\n",
       "      <td>Another area where private standard-setting emerged in the late 1990s was in relation to social or sustainable development reporting.</td>\n",
       "      <td>Another area where civilian standards began in the late 1990s was involved in social or sustainable progress reports.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As the last bit of light fades enjoy the scenery as you sail past ancient communities of fishermen that have lived for generations in floating villages on the water.</td>\n",
       "      <td>光の最後のビットは、あなたが水上の浮遊村で世代のために住んでいる古代の漁師のコミュニティを越えて航海するとき、景色を楽しむようになります。</td>\n",
       "      <td>The last bit of light will make you enjoy the scenery as you sail past communities of ancient fishermen who have lived for generations in floating villages on the water.</td>\n",
       "      <td>The last bit of light comes to enjoy the scenery when you sail across the ancient fishing community where you live for generations in floating villages on water.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                      en  \\\n",
       "0                         The company is targeting to increase the number of female staff in managerial positions in various business areas in the medium- to long-term.   \n",
       "1                                                                                                   Today there are an overwhelming number of payment methods available.   \n",
       "2                      There are many pieces that are simple, yet having a fairy-tale like ambience, so I think that anyone will be able to easily appreciate the works.   \n",
       "3                                                    Another area of private standard-setting to emerge in the late 1990’s concerned social or sustainability reporting.   \n",
       "4  As the last bit of light fades enjoy the scenery as you sail past ancient communities of fishermen that have lived for generations in floating villages on the water.   \n",
       "\n",
       "                                                                      jp  \\\n",
       "0                      今後、あらゆる領域で更に女性が活 躍し、管理職を担う女性が中長期的に増加することをめざしています。   \n",
       "1                                銀行送金に対応している全体的なブックメーカーの数はまだまだ少ないのが現状です。   \n",
       "2                            シンプルながらも童話のような感じを与える作品が多く、誰でも簡単に共感できると感じます。   \n",
       "3                   1990 年代後半に民間の規格設定が出現した別の領域は、社会的又は持続的発展報告 に係わるものであった。   \n",
       "4  光の最後のビットは、あなたが水上の浮遊村で世代のために住んでいる古代の漁師のコミュニティを越えて航海するとき、景色を楽しむようになります。   \n",
       "\n",
       "                                                                                                                                                              google_translation  \\\n",
       "0  Going forward, we aim to encourage more women to play an active role in all fields, and to increase the number of women in managerial positions over the medium to long term.   \n",
       "1                                                                     The current situation is that the overall number of bookmakers that support bank transfers is still small.   \n",
       "2                                                     Although many of the works are simple, they have a fairy tale-like feel, and I feel that anyone can easily relate to them.   \n",
       "3                                          Another area where private standard-setting emerged in the late 1990s was in relation to social or sustainable development reporting.   \n",
       "4      The last bit of light will make you enjoy the scenery as you sail past communities of ancient fishermen who have lived for generations in floating villages on the water.   \n",
       "\n",
       "                                                                                                                                                                   prediction  \n",
       "0  From now on, women in all walks of life and in all walks of life will be able to increase in the middle-term women who are more active and more active and more executive.  \n",
       "1                                                                                              The total number of bookmakers corresponding to bank transfers is still small.  \n",
       "2                                                  There are many simple works that give you the feeling of being a fairy tale, and I find it easy to sympathize with anyone.  \n",
       "3                                                       Another area where civilian standards began in the late 1990s was involved in social or sustainable progress reports.  \n",
       "4           The last bit of light comes to enjoy the scenery when you sail across the ancient fishing community where you live for generations in floating villages on water.  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = translation_google(test)\n",
    "test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
